model_name_or_path: /cache/exps/AtomThink/train_full/llama32-11b-vision/llava100k_amath/
device_map: "cuda:0"
trust_remote_code: true
print_param_status: false
prm_model: /prm
prm_device_map: "cuda:1"
prm_model_type: "qwen_math_prm"
infer_dtype: "float16"

### Test data
dataset_dir: data/test_data  # map your annotation to dataset_dir
dataset_name: R1V
image_dir: data/test_data/R1V/images
dataset: R1V/outline_dataset.json

template: mllama  # prompt template in src/llamafactory/data/template.py
cutoff_len: 4096  # model_max_length
max_samples: 2  # sampling your dataset
prompt: r1v  # base, cot, quick, slow, multimath_cot, r1v
answers_file: /cache/exps/AtomThink/train_full/llama32-11b-vision/llava100k_amath/

### inference
separate_eval: true
method: atomic
temperature: 0.2
top_p: 0.7
top_k: 50
max_new_tokens: 4096
repetition_penalty: 1.0
max_sampling_count: 30
max_single_step_sampling_count: 30
max_depth: 30
atomthink_beam_search_num: 2
candidate_num: 3
image_resolution: 313600