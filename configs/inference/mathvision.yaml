model_name_or_path: /cache/exps/AtomThink/train_full/llama32-11b-vision/llava100k_amath/
device_map: "cuda:0"
trust_remote_code: true
print_param_status: false
prm_model: /cache/data/huggingface_models/Qwen2.5-Math-PRM-7B
prm_device_map: "cuda:1"
prm_model_type: "qwen_math_prm"
infer_dtype: "float16"

### Test data
dataset_dir: data/test_data  # map your annotation to dataset_dir
dataset_name: MathVision
image_dir: data/test_data/MathVision
dataset: MathVision/test.jsonl
template: mllama  # prompt template in src/llamafactory/data/template.py
cutoff_len: 4096  # model_max_length
max_samples: 2 # sampling your dataset
prompt: slow  # base, cot, quick, slow
answers_file: /cache/exps/AtomThink/train_full/llama32-11b-vision/llava100k_amath/inference/
quick_match: false

### inference
method: slow
temperature: 0.2
top_p: 0.7
top_k: 50
max_new_tokens: 4096
repetition_penalty: 1.0
max_sampling_count: 300
max_single_step_sampling_count: 30
max_depth: 30
atomthink_beam_search_num: 2
candidate_num: 3
image_resolution: 313600